r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
#clean up
r_stats_text_corpus <- tm_map(r_stats_text_corpus, tolower)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()))
wordcloud(r_stats_text_corpus)
sessionInfo()
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, tolower, mc.cores=1)
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
#clean up
r_stats_text_corpus <- tm_map(r_stats_text_corpus, tolower, mc.cores=1)
r_stats_text <- sapply(r_stats, function(x) x$getText())
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, tolower, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
wordcloud(r_stats_text_corpus)
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
#clean up
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x) iconv(enc2utf8(x), sub = "byte"), mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, tolower, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
wordcloud(r_stats_text_corpus)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, tolower, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
wordcloud(r_stats_text_corpus)
wordcloud(r_stats_text_corpus, mc.cores=1)
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
#clean up
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
head(r_stats)
b <- writeCorpus(r_stats)
head(r_stats_text)
b <- writeCorpus(r_stats_text)
?Corpus
?tm
??tm
head(r_stats)
r_stats$getText()
?getText
??getText
r_stats_text <- sapply(r_stats, function(x) x$getText())
?VCorpus
?VectorSource
head(VectorSource(r_stats_text))
r_stats_text <- sapply(r_stats, function(x) x$getText())
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
wordcloud(r_stats_text_corpus, mc.cores=1)
?getTransformations
getTransformations(r_stats_text_corpus)
getTransformations()
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower))
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
#clean up
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
?iconv
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
#clean up
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x) iconv(x, to='UTF-8', sub='byte'))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(function(x) iconv(x, to='UTF-8', sub='byte')))
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
#clean up
r_stats_text_corpus <- tm_map(r_stats_text_corpus,
content_transformer(function(x) iconv(x, to='UTF-8', sub='byte')),
mc.cores=1
)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text <- sapply(r_stats, function(x) x$getText())
#create corpus
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
#clean up
r_stats_text_corpus <- tm_map(r_stats_text_corpus,
content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1
)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
wordcloud(r_stats_text_corpus, mc.cores=1)
bioinformatics <- searchTwitter("#bioinformatics", n=1500, cainfo="cacert.pem")
bioinformatics_text <- sapply(bioinformatics, function(x) x$getText())
bioinformatics_text_corpus <- Corpus(VectorSource(bioinformatics_text))
bioinformatics_text_corpus <- tm_map(bioinformatics_text_corpus, content_transformer(tolower), mc.cores=1)
bioinformatics_text <- sapply(bioinformatics, function(x) x$getText())
bioinformatics_text_corpus <- Corpus(VectorSource(bioinformatics_text))
bioinformatics_text_corpus <- tm_map(bioinformatics_text_corpus,
content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1
)
bioinformatics_text_corpus <- tm_map(bioinformatics_text_corpus, content_transformer(tolower), mc.cores=1)
bioinformatics_text_corpus <- tm_map(bioinformatics_text_corpus, removePunctuation, mc.cores=1)
bioinformatics_text_corpus <- tm_map(bioinformatics_text_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
wordcloud(bioinformatics_text_corpus, mc.cores=1)
)
bioinformatics <- searchTwitter("#bioinformatics", n=1500)
warnings()
head(bioinformatics)
bioinformatics_text <- sapply(bioinformatics, function(x) x$getText())
bioinformatics_text_corpus <- Corpus(VectorSource(bioinformatics_text))
bioinformatics_text_corpus <- tm_map(bioinformatics_text_corpus,
content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1
)
bioinformatics_text_corpus <- tm_map(bioinformatics_text_corpus, content_transformer(tolower), mc.cores=1)
bioinformatics_text_corpus <- tm_map(bioinformatics_text_corpus, removePunctuation, mc.cores=1)
bioinformatics_text_corpus <- tm_map(bioinformatics_text_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
wordcloud(bioinformatics_text_corpus)
warnings()
library(RColorBrewer)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(bioinformatics_text_corpus,min.freq=2,max.words=100, random.order=T, colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10,max.words=100, random.order=T, colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10,max.words=1000, random.order=T, colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=100,max.words=1000, random.order=T, colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=20, random.order=T, colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, scale = 1, colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, scale=c(0,1), colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, res=300, colors=pal2)
warnings()
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, colors=pal2)
?wordcloud
wordcloud(c(letters, LETTERS, 0:9), seq(1, 1000, len = 62))
wordcloud(c(letters, LETTERS, 0:9), seq(1, 1000, len = 62), scale=c(8,.5))
warnings()
wordcloud(c(letters, LETTERS, 0:9), seq(1, 1000, len = 62), scale=c(4,.5))
wordcloud(c(letters, LETTERS, 0:9), seq(1, 1000, len = 62), scale=c(2,.5))
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, scale=c(2,1), colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, scale=c(2,0.2), colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, scale=c(2,0.2), colors=pal2)
wordcloud(bioinformatics_text_corpus,min.freq=10, random.order=T, colors=pal2)
source("http://bioconductor.org/biocLite.R")
biocLite("genomation")
q()
list.files()
library("twitteR")
library("ROAuth")
load("twitter_authentication.Rdata")
load("twitter_authentication.Rdata")
registerTwitterOAuth(cred)
me <- getUser("davetang31")
library("wordcloud")
library("tm")
mentions <- searchTwitter("@davetang31", n=100)
mentions <- searchTwitter("@davetang31", n=100)
r_stats<- searchTwitter("#Rstats", n=1500, cainfo="cacert.pem")
r_stats<- searchTwitter("#Rstats", n=100, cainfo="cacert.pem")
r_stats<- searchTwitter("@davetang31", n=100, cainfo="cacert.pem")
r_stats<- searchTwitter("davetang31", n=100, cainfo="cacert.pem")
r_stats <- searchTwitter("davetang31", n=10, cainfo="cacert.pem")
me <- searchTwitter("@davetang31", n=10)
me
me <- searchTwitter("@davetang31", n=10)
me <- searchTwitter("@davetang31", n=15)
me
me <- searchTwitter("@davetang31", n=15, since="20121111")
me <- searchTwitter("@davetang31", n=15, since="2012-11-11")
me <- searchTwitter("@davetang31", n=15, since="2012-11-11")
me
q()
source("http://bioconductor.org/biocLite.R")
biocLite("genomation")
library("twitteR")
library("ROAuth")
library("wordcloud")
library("tm")
load("twitter_authentication.Rdata")
registerTwitterOAuth(cred)
me <- getUser("davetang31")
me <- searchTwitter("@davetang31", n=15, since="2012-11-11")
me
me <- searchTwitter("@davetang31", n=30, since="2012-11-11")
q()
3/2.5
5/5.2
5/5.5
mean(91,82,87,75,92,77)
mean(c(91,82,87,75,92,77))
mean(c(8,10,15,17,12,1))
sd(c(8,10,15,17,12,1))
?sd
mean(c(51,58,62,27))
var(c(51,58,62,27))
q()
source("http://bioconductor.org/biocLite.R")
biocLite("genomation")
biocLite()
q()
370*529
198*66
9030/14
2782*13
3/0.75
0.528*14.5
9086/77
9.01*59.7
63/45
0.666*613
0.286*77.5
a <- c(46,1,20,16,12,2)
mean(a)
var(a)
source("http://bioconductor.org/biocLite.R")
biocLite("genomation")
q()
q()
source("http://bioconductor.org/biocLite.R")
biocLite()
source("http://bioconductor.org/biocLite.R")
biocLite("edgeR")
library(edgeR)
control_1 <- rep(10,50)
control_1
df <- data.frame(c1=control_1,
c2=control_2,
p1=patient_1,
p2=patient_2)
control_1 <- rep(10, 50)
control_2 <- rep(10, 50)
patient_1 <- rep(20, 25)
patient_2 <- rep(20, 25)
df <- data.frame(c1=control_1,
c2=control_2,
p1=patient_1,
p2=patient_2)
df
head(df)
d <- readDGE(df)
dim(df)
group <- c('control','control','patient','patient')
d <- readDGE(counts=df, group=group)
d <- readDGE(counts=df, group=group)
library(edgeR)
control_1 <- rep(10, 50)
control_2 <- rep(10, 50)
patient_1 <- rep(20, 25)
patient_2 <- rep(20, 25)
df <- data.frame(c1=control_1,
c2=control_2,
p1=patient_1,
p2=patient_2)
group <- c('control','control','patient','patient')
d <- DGEList(counts=df, group=group)
d
tail(df)
length(patient_2)
control_1 <- rep(10, 50)
control_2 <- rep(10, 50)
patient_1 <- c(rep(20, 25),rep(0,25))
patient_2 <- c(rep(20, 25),rep(0,25))
df <- data.frame(c1=control_1,
c2=control_2,
p1=patient_1,
p2=patient_2)
group <- c('control','control','patient','patient')
d <- DGEList(counts=df, group=group)
d
d <- calcNormFactors(d)
d
d
control_1 <- rep(10, 50)
control_2 <- rep(10, 50)
patient_1 <- c(rep(20, 25),rep(0,25))
patient_2 <- c(rep(20, 25),rep(0,25))
df <- data.frame(c1=control_1,
c2=control_2,
p1=patient_1,
p2=patient_2)
group <- c('control','control','patient','patient')
d <- DGEList(counts=df, group=group)
d
d <- calcNormFactors(d)
d <- calcNormFactors(d)
d
d <- DGEList(counts=df, group=group)
d
d <- estimateCommonDisp(d)
d$samples$lib.size
d$pseudo.lib.size
colSums(d$pseudo.counts)
d$common.dispersion
sqrt(d$common.dispersion)
de <- exactTest(d)
sum(p.adjust(de.com$table$p.value,method="BH") < 0.05)
sum(p.adjust(de$table$p.value,method="BH") < 0.05)
de
dim(de$table)
head(de$table)
tail(de$table)
p.adjust(de$table$PValue, method="BH")
table(p.adjust(de$table$PValue, method="BH")<0.05)
d <- DGEList(counts=df, group=group)
d <- estimateCommonDisp(d)
d$samples$lib.size
d$pseudo.lib.size
colSums(d$pseudo.counts)
d$common.dispersion
sqrt(d$common.dispersion)
d$pseudo.lib.size
d$pseudo.lib.size
d$counts
d$AveLogCPM
d <- DGEList(counts=df, group=group)
d <- estimateCommonDisp(d)
de_norm <- exactTest(d)
table(p.adjust(de$table$PValue, method="BH")<0.05)
table(p.adjust(de_norm$table$PValue, method="BH")<0.05)
head(de_norm$table)
head(de$table)
control_1 <- rep(10, 50)
control_2 <- rep(10, 50)
patient_1 <- c(rep(20, 25),rep(0,25))
patient_2 <- c(rep(20, 25),rep(0,25))
df <- data.frame(c1=control_1,
c2=control_2,
p1=patient_1,
p2=patient_2)
group <- c('control','control','patient','patient')
d <- DGEList(counts=df, group=group)
d <- calcNormFactors(d)
d <- estimateCommonDisp(d)
de_norm <- exactTest(d)
table(p.adjust(de_norm$table$PValue, method="BH")<0.05)
?calcNormFactors
calcNormFactors.default
calcNormFactors.default()
?calcNormFactors
control_1 <- rep(10, 50)
control_2 <- rep(10, 50)
patient_1 <- c(rep(20, 25),rep(0,25))
patient_2 <- c(rep(20, 25),rep(0,25))
df <- data.frame(c1=control_1,
c2=control_2,
p1=patient_1,
p2=patient_2)
df
head(df)
tail(df)
colSums(df)
class(d)
control_1 <- rep(10, 50)
control_2 <- rep(10, 50)
patient_1 <- c(rep(20, 25),rep(0,25))
patient_2 <- c(rep(20, 25),rep(0,25))
df <- data.frame(c1=control_1,
c2=control_2,
p1=patient_1,
p2=patient_2)
group <- c('control','control','patient','patient')
d <- DGEList(counts=df, group=group)
de_norm <- exactTest(d)
d <- estimateCommonDisp(d)
de_norm <- exactTest(d)
control_1 <- rep(10, 50)
control_2 <- rep(10, 50)
patient_1 <- c(rep(20, 25),rep(0,25))
patient_2 <- c(rep(20, 25),rep(0,25))
df <- data.frame(c1=control_1,
c2=control_2,
p1=patient_1,
p2=patient_2)
group <- c('control','control','patient','patient')
d <- DGEList(counts=df, group=group)
no_norm <- estimateCommonDisp(d)
no_norm <- exactTest(no_norm)
table(p.adjust(no_norm$table$PValue, method="BH")<0.05)
TMM <- calcNormFactors(d, method="TMM")
TMM <- estimateCommonDisp(TMM)
TMM <- exactTest(TMM)
table(p.adjust(TMM$table$PValue, method="BH")<0.05)
TMM
TMM <- calcNormFactors(d, method="TMM")
TMM
TMM <- estimateCommonDisp(TMM)
TMM <- exactTest(TMM)
table(p.adjust(TMM$table$PValue, method="BH")<0.05)
TMM$table
RLE <- calcNormFactors(d, method="RLE")
RLE
RLE <- calcNormFactors(d, method="RLE")
RLE
RLE <- estimateCommonDisp(RLE)
RLE <- exactTest(RLE)
table(p.adjust(RLE$table$PValue, method="BH")<0.05)
uq <- calcNormFactors(d, method="upperquartile")
uq
uq <- calcNormFactors(d, method="none")
uq
uq <- calcNormFactors(d, method="upperquartile")
uq
uq <- estimateCommonDisp(uq)
ua <- exactTest(ua)
table(p.adjust(uq$table$PValue, method="BH")<0.05)
uq <- calcNormFactors(d, method="upperquartile")
uq
uq <- estimateCommonDisp(uq)
ua <- exactTest(uq)
table(p.adjust(uq$table$PValue, method="BH")<0.05)
uq <- calcNormFactors(d, method="upperquartile")
uq
uq <- estimateCommonDisp(uq)
uq <- exactTest(uq)
table(p.adjust(uq$table$PValue, method="BH")<0.05)
data <- read.table("http://sites.google.com/site/davismcc/useful-documents/pnas_expression.txt")
data <- read.table(url("http://sites.google.com/site/davismcc/useful-documents/pnas_expression.txt"))
data <- read.table(file=url(http://sites.google.com/site/davismcc/useful-documents/pnas_expression.txt),
header=T)
data <- read.table(file=url('http://sites.google.com/site/davismcc/useful-documents/pnas_expression.txt'),
header=T)
data <- read.table(file=url('https://dl.dropboxusercontent.com/u/15251811/pnas_expression.txt'),
header=T)
require(RCurl)
require(RCurl)
my_file <- getURL("https://dl.dropboxusercontent.com/u/15251811/pnas_expression.txt")
data <- read.table(textConnection(my_file))
dim(data)
head(data)
require(RCurl)
my_file <- getURL("https://dl.dropboxusercontent.com/u/15251811/pnas_expression.txt")
data <- read.table(textConnection(my_file), header=T, sep="\t")
dim(data)
head(data)
d <- data[,2:8]
rownames(d) <- data[,1]
group <- c(rep("Control",4),rep("DHT",3))
d <- DGEList(counts = d, group=group)
dim(d)
head(d
)
#no normalisation
no_norm <- estimateCommonDisp(d)
no_norm <- exactTest(no_norm)
table(p.adjust(no_norm$table$PValue, method="BH")<0.05)
#TMM
TMM <- calcNormFactors(d, method="TMM")
TMM
TMM <- estimateCommonDisp(TMM)
TMM <- exactTest(TMM)
table(p.adjust(TMM$table$PValue, method="BH")<0.05)
RLE <- calcNormFactors(d, method="RLE")
RLE
RLE <- estimateCommonDisp(RLE)
RLE <- exactTest(RLE)
table(p.adjust(RLE$table$PValue, method="BH")<0.05)
uq <- calcNormFactors(d, method="upperquartile")
uq
uq <- estimateCommonDisp(uq)
uq <- exactTest(uq)
table(p.adjust(uq$table$PValue, method="BH")<0.05)
q()
q()
library(slidify)
author("slidify_test")
?getwd
?FANTOM3and4CAGE
??FANTOM3and4CAGE
matrix(rnorm(100),nrow=10)
image(matrix(rnorm(100),nrow=10))
publish('davetang/cage_r')
publish('davetang', 'cage_r')
publish('cage_r', 'davetang')
publish('cage_r', 'davetang')
publish('cage_r', 'davetang')
q()
